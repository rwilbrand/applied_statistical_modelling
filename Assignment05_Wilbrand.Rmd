---
title: "ASM Assignment 05"
author: "Robert Wilbrand"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, message = FALSE, warning = FALSE}
# load necessary packages
library(flextable)
library(brms)
library(tidyverse)

# set global options
theme_set(theme_minimal())
knitr::opts_knit$set(root.dir = "C:/MSc GCG/2021_SoSe/ASM")
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
options(scipen = 8) # disables scientific notation up to 8 digits

# Wrapper function to set a specified seed prior to function execution
# useful because it leaves the seed outside the function unaffected
seedFunc <- function(seed, func, ...){
  set.seed(seed)
  func(...)
}
```

```{r}
# Define data
birdMatrix <- rbind("Island 1" = rep(.2, 5),
                    "Island 2" = c(.8,.1,.05,.025,.025),
                    "Island 3" = c(.05,.15,.7,.05,.05))
colnames(birdMatrix) <- str_c("Species ", LETTERS[1:5])
```

## 7H3.
Consider three fictional Polynesian islands. On each there is a Royal Ornithologist charged by the king with surveying the bird population. They have each found the following proportions of 5 important bird species:

```{r, echo=FALSE}
flextable(birdMatrix %>%
            as.data.frame %>%
            rownames_to_column(var = " "),
          cwidth = 1)
```

Notice that each row sums to 1, all the birds. This problem has two parts. It is not computationally complicated. But it is conceptually tricky. First, compute the entropy of each island’s bird distribution. Interpret these entropy values. Second, use each island’s bird distribution to predict the other two. This means to compute the KL divergence of each island from the others, treating each island as if it were a statistical model of the other islands. You should end up with 6 different KL divergence values. Which island predicts the others best? Why?

```{r}
# Define entropy and KL divergence functions
entropy <- function(p) -sum(p * log(p))
divKL <- function(p, q) sum(p * log(p/q))

# Iterate over rows to determine entropy
map_dbl(1:3, ~entropy(birdMatrix[.x,]))
```

Entropy is highest for island 1, where each species occurs with equal frequency, and lowest for island 2, which is dominated by species A. Information entropy is generally lower the more lop-sided a distribution is, which is illustrated by this example

```{r}
# Create a dataframe of all possible combinations
combis <- expand.grid(1:3, 1:3) %>% filter(Var1 != Var2)

# Iterate over combinations to determine KL divergence
islandKLs <- pmap_dbl(combis, ~divKL(birdMatrix[.x,], birdMatrix[.y,]))

# Combine into one dataframe, arrange by KL divergence
islandModels <-
  transmute(combis, "Model" = str_c(Var1, " predicts ", Var2)) %>% 
  bind_cols("KL divergence" = islandKLs) %>% 
  arrange(`KL divergence`)

flextable(islandModels, cwidth = 1.5)
```

Island 2 and 3 do a terrible job of predicting each other's bird distribution. That's not surprising given that different bird species dominate on each. The best result is achieved by island 3 predicting island 1, but the opposite direction achieves an almost identical value (which is not generally true for any two distributions).  
The way I interpret this is that an equal distribution will never do great at predicting lop-sided distributions, but it will always do a reasonable job for at least part of the distribution. The same logic applies vice versa.

## WaffleDivorce Reloaded

```{r}
# Reload the data
data(WaffleDivorce, package = "rethinking")

# Prepare the data
WaffleDivorce <- as_tibble(WaffleDivorce) %>% 
  mutate("A" = scale(MedianAgeMarriage) %>% as.numeric,
         "M" = scale(Marriage) %>% as.numeric,
         "D" = scale(Divorce) %>% as.numeric,
         across(South, as.factor))
```

```{r, eval=FALSE}
# Not evaluated, models are already saved
listOfDivorceModels <- list(
  divorce1 <- brm(
    data = WaffleDivorce,
    family = gaussian,
    D ~ 0 + A + M + South,
    prior = c(#prior(normal(0, 0.2), class = Intercept),
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sigma)),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    seed = 4321),

  divorce2 <- brm(
    data = WaffleDivorce,
    family = gaussian,
    D ~ 0 + A + South,
    prior = c(#prior(normal(0, 0.2), class = Intercept),
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sigma)),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    seed = 4321),

  divorce3 <- brm(
    data = WaffleDivorce,
    family = gaussian,
    D ~ 0 + M + South,
    prior = c(#prior(normal(0, 0.2), class = Intercept),
      prior(normal(0, 0.5), class = b),
      prior(exponential(1), class = sigma)),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    seed = 4321),
  
  divorce4 <- brm(
    data = WaffleDivorce,
    family = gaussian,
    D ~ 1 + A + M,
    prior = c(prior(normal(0, 0.2), class = Intercept),
              prior(normal(0, 0.5), class = b),
              prior(exponential(1), class = sigma)),
    iter = 2000, warmup = 1000, cores = 4, chains = 4,
    seed = 4321)
  )

saveRDS(listOfDivorceModels, "divorceList.rds")
```

```{r}
# Add criteria to models
listOfDivorceModels <- read_rds("divorceList.rds") %>% 
  map(~add_criterion(.x, criterion = c("waic", "loo")))

map(listOfDivorceModels, waic)
map(listOfDivorceModels, loo)

(waicWeights <-
    do_call("model_weights", c(listOfDivorceModels, weights = "waic"))) %>%
  round(2)

# Compare models according to PSIS or WAIC
elpd__loo <- do_call("loo_compare", c(listOfDivorceModels, criterion = "loo"))
elpd_waic <- do_call("loo_compare", c(listOfDivorceModels, criterion = "waic"))
rownames(elpd__loo) <- str_replace(rownames(elpd__loo), ".x", "divorce")
rownames(elpd_waic) <- str_replace(rownames(elpd_waic), ".x", "divorce")
print(elpd__loo)
print(elpd_waic)
```

The ELPD is similar for both criteria. The model using age at marriage and Southness performs best. However, the calculated Akaike weights suggest that the model 1 and 4 are at least reasonable enough to be included when using model averaging.

